#!/usr/bin/env python3
"""
íŒŒì¼ ê²½ë¡œ: scripts/analyze_database_status.py

SQLite ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ì™„ì „ ë¶„ì„ ìŠ¤í¬ë¦½íŠ¸
- í…Œì´ë¸”ë³„ ë ˆì½”ë“œ ìˆ˜ ë° êµ¬ì¡° ë¶„ì„
- ë°ì´í„° í’ˆì§ˆ ì²´í¬
- ë‚ ì§œ ë²”ìœ„ ë° ëˆ„ë½ ë°ì´í„° í™•ì¸
- MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ìœ„í•œ ê¶Œì¥ì‚¬í•­ ì œì‹œ
"""
import sys
import os
import sqlite3
from pathlib import Path
from datetime import datetime, timedelta
import json

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.core.config import Config
from src.core.database import get_database_manager
from sqlalchemy import text


class DatabaseAnalyzer:
    """ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë¶„ì„ê¸°"""

    def __init__(self):
        self.config = Config()
        self.db_manager = get_database_manager()
        self.analysis_result = {}

        # SQLite ì§ì ‘ ì—°ê²° (ìƒì„¸ ë¶„ì„ìš©)
        self.db_path = self._get_db_path()

    def _get_db_path(self) -> Path:
        """SQLite DB íŒŒì¼ ê²½ë¡œ í™•ì¸"""
        db_path = Path("./data/stock_data.db")
        if not db_path.exists():
            # ë‹¤ë¥¸ ê°€ëŠ¥í•œ ê²½ë¡œë“¤ í™•ì¸
            possible_paths = [
                Path("./data/stock_data_dev.db"),
                Path("./stock_data.db"),
                Path("../data/stock_data.db")
            ]

            for path in possible_paths:
                if path.exists():
                    db_path = path
                    break

        return db_path.absolute()

    def analyze_database(self) -> dict:
        """ë°ì´í„°ë² ì´ìŠ¤ ì™„ì „ ë¶„ì„"""
        print("ğŸ” SQLite ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë¶„ì„ ì‹œì‘")
        print("=" * 60)

        try:
            # 1. ê¸°ë³¸ ì •ë³´
            self._analyze_basic_info()

            # 2. í…Œì´ë¸” êµ¬ì¡° ë° ë ˆì½”ë“œ ìˆ˜
            self._analyze_tables()

            # 3. ì£¼ì‹ ê¸°ë³¸ì •ë³´ ë¶„ì„
            self._analyze_stocks_table()

            # 4. ì¼ë´‰ ë°ì´í„° ë¶„ì„
            self._analyze_daily_tables()

            # 5. ìˆ˜ì§‘ ì§„í–‰ìƒí™© ë¶„ì„
            self._analyze_collection_progress()

            # 6. ë°ì´í„° í’ˆì§ˆ ì²´í¬
            self._analyze_data_quality()

            # 7. ì„±ëŠ¥ ë¶„ì„
            self._analyze_performance()

            # 8. MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥ì‚¬í•­
            self._generate_migration_recommendations()

            # 9. ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥
            self._print_final_report()

            return self.analysis_result

        except Exception as e:
            print(f"âŒ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return {"error": str(e)}

    def _analyze_basic_info(self):
        """ê¸°ë³¸ ì •ë³´ ë¶„ì„"""
        print("ğŸ“Š 1. ê¸°ë³¸ ì •ë³´ ë¶„ì„")
        print("-" * 30)

        try:
            # DB íŒŒì¼ ì •ë³´
            if self.db_path.exists():
                file_size = self.db_path.stat().st_size
                file_size_mb = file_size / (1024 * 1024)

                print(f"ğŸ“ DB íŒŒì¼ ê²½ë¡œ: {self.db_path}")
                print(f"ğŸ’¾ DB íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB ({file_size:,} bytes)")

                # ë§ˆì§€ë§‰ ìˆ˜ì • ì‹œê°„
                mtime = datetime.fromtimestamp(self.db_path.stat().st_mtime)
                print(f"ğŸ“… ë§ˆì§€ë§‰ ìˆ˜ì •: {mtime.strftime('%Y-%m-%d %H:%M:%S')}")

                self.analysis_result['basic_info'] = {
                    'file_path': str(self.db_path),
                    'file_size_mb': round(file_size_mb, 2),
                    'file_size_bytes': file_size,
                    'last_modified': mtime.isoformat()
                }
            else:
                print(f"âŒ DB íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {self.db_path}")
                self.analysis_result['basic_info'] = {'error': 'DB íŒŒì¼ ì—†ìŒ'}

        except Exception as e:
            print(f"âŒ ê¸°ë³¸ ì •ë³´ ë¶„ì„ ì‹¤íŒ¨: {e}")

    def _analyze_tables(self):
        """í…Œì´ë¸” êµ¬ì¡° ë° ë ˆì½”ë“œ ìˆ˜ ë¶„ì„"""
        print(f"\nğŸ“‹ 2. í…Œì´ë¸” êµ¬ì¡° ë¶„ì„")
        print("-" * 30)

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ì „ì²´ í…Œì´ë¸” ëª©ë¡
                cursor.execute("""
                    SELECT name, type FROM sqlite_master 
                    WHERE type IN ('table', 'view') 
                    ORDER BY name
                """)

                tables = cursor.fetchall()

                print(f"ğŸ“Š ì´ í…Œì´ë¸”/ë·° ê°œìˆ˜: {len(tables)}ê°œ")
                print()

                table_info = {}

                for table_name, table_type in tables:
                    try:
                        # ë ˆì½”ë“œ ìˆ˜ ì¡°íšŒ
                        cursor.execute(f"SELECT COUNT(*) FROM {table_name}")
                        count = cursor.fetchone()[0]

                        # í…Œì´ë¸” ìŠ¤í‚¤ë§ˆ ì •ë³´
                        cursor.execute(f"PRAGMA table_info({table_name})")
                        columns = cursor.fetchall()

                        table_info[table_name] = {
                            'type': table_type,
                            'record_count': count,
                            'column_count': len(columns),
                            'columns': [(col[1], col[2]) for col in columns]  # (name, type)
                        }

                        print(f"ğŸ“‹ {table_name} ({table_type})")
                        print(f"   ğŸ“Š ë ˆì½”ë“œ ìˆ˜: {count:,}ê°œ")
                        print(f"   ğŸ·ï¸ ì»¬ëŸ¼ ìˆ˜: {len(columns)}ê°œ")

                        if table_name.startswith('daily_prices_'):
                            stock_code = table_name.replace('daily_prices_', '')
                            print(f"   ğŸ“ˆ ì¢…ëª©ì½”ë“œ: {stock_code}")

                        print()

                    except Exception as e:
                        print(f"âŒ {table_name} ë¶„ì„ ì‹¤íŒ¨: {e}")

                self.analysis_result['tables'] = table_info

        except Exception as e:
            print(f"âŒ í…Œì´ë¸” ë¶„ì„ ì‹¤íŒ¨: {e}")

    def _analyze_stocks_table(self):
        """stocks í…Œì´ë¸” ìƒì„¸ ë¶„ì„"""
        print(f"ğŸ“ˆ 3. ì£¼ì‹ ê¸°ë³¸ì •ë³´ (stocks) ë¶„ì„")
        print("-" * 30)

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ê¸°ë³¸ í†µê³„
                cursor.execute("SELECT COUNT(*) FROM stocks")
                total_stocks = cursor.fetchone()[0]

                # ì‹œì¥ë³„ ë¶„í¬
                cursor.execute("""
                    SELECT market, COUNT(*) 
                    FROM stocks 
                    GROUP BY market 
                    ORDER BY COUNT(*) DESC
                """)
                market_dist = cursor.fetchall()

                # í™œì„±/ë¹„í™œì„± ë¶„í¬
                cursor.execute("""
                    SELECT is_active, COUNT(*) 
                    FROM stocks 
                    GROUP BY is_active
                """)
                active_dist = cursor.fetchall()

                # ìµœì‹  ì—…ë°ì´íŠ¸ í˜„í™©
                cursor.execute("""
                    SELECT 
                        DATE(last_updated) as update_date, 
                        COUNT(*) as count
                    FROM stocks 
                    WHERE last_updated IS NOT NULL
                    GROUP BY DATE(last_updated)
                    ORDER BY update_date DESC
                    LIMIT 10
                """)
                update_dist = cursor.fetchall()

                # ê°€ê²© ë²”ìœ„ ë¶„ì„
                cursor.execute("""
                    SELECT 
                        MIN(current_price) as min_price,
                        MAX(current_price) as max_price,
                        AVG(current_price) as avg_price,
                        COUNT(CASE WHEN current_price > 0 THEN 1 END) as valid_prices
                    FROM stocks
                """)
                price_stats = cursor.fetchone()

                print(f"ğŸ“Š ì´ ì¢…ëª© ìˆ˜: {total_stocks:,}ê°œ")
                print()

                print("ğŸ“ˆ ì‹œì¥ë³„ ë¶„í¬:")
                for market, count in market_dist:
                    percentage = (count / total_stocks * 100) if total_stocks > 0 else 0
                    print(f"   {market or 'NULL'}: {count:,}ê°œ ({percentage:.1f}%)")
                print()

                print("ğŸ”„ í™œì„± ìƒíƒœ ë¶„í¬:")
                for is_active, count in active_dist:
                    status = "í™œì„±" if is_active == 1 else "ë¹„í™œì„±"
                    percentage = (count / total_stocks * 100) if total_stocks > 0 else 0
                    print(f"   {status}: {count:,}ê°œ ({percentage:.1f}%)")
                print()

                print("ğŸ“… ìµœê·¼ ì—…ë°ì´íŠ¸ í˜„í™©:")
                for update_date, count in update_dist[:5]:
                    print(f"   {update_date}: {count:,}ê°œ")
                print()

                if price_stats:
                    min_price, max_price, avg_price, valid_prices = price_stats
                    print("ğŸ’° ê°€ê²© ì •ë³´:")
                    print(f"   ìµœì €ê°€: {min_price:,}ì›")
                    print(f"   ìµœê³ ê°€: {max_price:,}ì›")
                    print(f"   í‰ê· ê°€: {avg_price:,.0f}ì›")
                    print(f"   ìœ íš¨ ê°€ê²©: {valid_prices:,}ê°œ")

                self.analysis_result['stocks_analysis'] = {
                    'total_count': total_stocks,
                    'market_distribution': dict(market_dist),
                    'active_distribution': dict(active_dist),
                    'recent_updates': dict(update_dist),
                    'price_stats': {
                        'min': min_price,
                        'max': max_price,
                        'avg': round(avg_price, 2) if avg_price else 0,
                        'valid_count': valid_prices
                    }
                }

        except Exception as e:
            print(f"âŒ stocks í…Œì´ë¸” ë¶„ì„ ì‹¤íŒ¨: {e}")

    def _analyze_daily_tables(self):
        """ì¼ë´‰ ë°ì´í„° í…Œì´ë¸”ë“¤ ë¶„ì„"""
        print(f"\nğŸ“Š 4. ì¼ë´‰ ë°ì´í„° ë¶„ì„")
        print("-" * 30)

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # daily_prices_ í…Œì´ë¸” ëª©ë¡
                cursor.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name LIKE 'daily_prices_%'
                    ORDER BY name
                """)

                daily_tables = [row[0] for row in cursor.fetchall()]

                print(f"ğŸ“ˆ ì¼ë´‰ í…Œì´ë¸” ê°œìˆ˜: {len(daily_tables)}ê°œ")

                if not daily_tables:
                    print("âš ï¸ ì¼ë´‰ ë°ì´í„° í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                    self.analysis_result['daily_analysis'] = {
                        'table_count': 0,
                        'total_records': 0,
                        'average_records_per_stock': 0,
                        'date_range': None,
                        'sample_stocks': {}
                    }
                    return

                # ê° í…Œì´ë¸” ë¶„ì„
                total_records = 0
                date_ranges = []
                stock_analysis = {}

                print(f"\nğŸ“Š ì¢…ëª©ë³„ ì¼ë´‰ ë°ì´í„° ë¶„ì„ (ìƒìœ„ 10ê°œ):")

                for i, table in enumerate(daily_tables[:10]):
                    stock_code = table.replace('daily_prices_', '')

                    try:
                        # ë ˆì½”ë“œ ìˆ˜
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]
                        total_records += count

                        # ë‚ ì§œ ë²”ìœ„
                        cursor.execute(f"""
                            SELECT MIN(date), MAX(date) 
                            FROM {table} 
                            WHERE date IS NOT NULL
                        """)
                        date_range = cursor.fetchone()

                        if date_range and date_range[0]:
                            min_date, max_date = date_range
                            date_ranges.append((min_date, max_date))

                            print(f"   ğŸ“ˆ {stock_code}: {count:,}ê°œ ë ˆì½”ë“œ ({min_date} ~ {max_date})")

                            stock_analysis[stock_code] = {
                                'record_count': count,
                                'date_range': (min_date, max_date)
                            }
                        else:
                            print(f"   ğŸ“ˆ {stock_code}: {count:,}ê°œ ë ˆì½”ë“œ (ë‚ ì§œ ì •ë³´ ì—†ìŒ)")

                    except Exception as e:
                        print(f"âŒ {table} ë¶„ì„ ì‹¤íŒ¨: {e}")
                        continue

                # ë‚˜ë¨¸ì§€ í…Œì´ë¸”ë“¤ë„ ì¹´ìš´íŠ¸ì— í¬í•¨ (ìƒì„¸ ì •ë³´ ì—†ì´)
                for table in daily_tables[10:]:
                    try:
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]
                        total_records += count
                    except:
                        continue

                if len(daily_tables) > 10:
                    print(f"   ... ì™¸ {len(daily_tables) - 10}ê°œ ì¢…ëª©")

                # ì „ì²´ í†µê³„
                print(f"\nğŸ“Š ì „ì²´ ì¼ë´‰ ë°ì´í„° í†µê³„:")
                print(f"   ğŸ“ˆ ì´ ë ˆì½”ë“œ ìˆ˜: {total_records:,}ê°œ")

                if date_ranges:
                    overall_min = min(dr[0] for dr in date_ranges)
                    overall_max = max(dr[1] for dr in date_ranges)
                    print(f"   ğŸ“… ì „ì²´ ë‚ ì§œ ë²”ìœ„: {overall_min} ~ {overall_max}")
                else:
                    overall_min = overall_max = None

                # í‰ê·  ë ˆì½”ë“œ ìˆ˜
                if daily_tables:
                    avg_records = total_records / len(daily_tables)
                    print(f"   ğŸ“Š ì¢…ëª©ë‹¹ í‰ê· : {avg_records:.0f}ê°œ ë ˆì½”ë“œ")
                else:
                    avg_records = 0

                self.analysis_result['daily_analysis'] = {
                    'table_count': len(daily_tables),
                    'total_records': total_records,
                    'average_records_per_stock': round(avg_records, 0) if daily_tables else 0,
                    'date_range': (overall_min, overall_max) if date_ranges else None,
                    'sample_stocks': stock_analysis
                }

        except Exception as e:
            print(f"âŒ ì¼ë´‰ ë°ì´í„° ë¶„ì„ ì‹¤íŒ¨: {e}")

    def _analyze_collection_progress(self):
        """ìˆ˜ì§‘ ì§„í–‰ìƒí™© ë¶„ì„"""
        print(f"\nğŸ“‹ 5. ìˆ˜ì§‘ ì§„í–‰ìƒí™© ë¶„ì„")
        print("-" * 30)

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # collection_progress í…Œì´ë¸” ì¡´ì¬ í™•ì¸
                cursor.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name='collection_progress'
                """)

                if not cursor.fetchone():
                    print("â„¹ï¸ collection_progress í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
                    return

                # ìƒíƒœë³„ ë¶„í¬
                cursor.execute("""
                    SELECT status, COUNT(*) 
                    FROM collection_progress 
                    GROUP BY status 
                    ORDER BY COUNT(*) DESC
                """)
                status_dist = cursor.fetchall()

                # ì‹œë„ íšŸìˆ˜ ë¶„í¬
                cursor.execute("""
                    SELECT attempt_count, COUNT(*) 
                    FROM collection_progress 
                    GROUP BY attempt_count 
                    ORDER BY attempt_count
                """)
                attempt_dist = cursor.fetchall()

                # ìµœê·¼ í™œë™
                cursor.execute("""
                    SELECT stock_code, status, last_attempt_time, data_count
                    FROM collection_progress 
                    WHERE last_attempt_time IS NOT NULL
                    ORDER BY last_attempt_time DESC 
                    LIMIT 5
                """)
                recent_activity = cursor.fetchall()

                print("ğŸ“Š ìƒíƒœë³„ ë¶„í¬:")
                total_progress = sum(count for _, count in status_dist)
                for status, count in status_dist:
                    percentage = (count / total_progress * 100) if total_progress > 0 else 0
                    print(f"   {status}: {count:,}ê°œ ({percentage:.1f}%)")

                print(f"\nğŸ”„ ì‹œë„ íšŸìˆ˜ ë¶„í¬:")
                for attempt, count in attempt_dist:
                    print(f"   {attempt}íšŒ: {count:,}ê°œ")

                print(f"\nğŸ“… ìµœê·¼ í™œë™ (ìƒìœ„ 5ê°œ):")
                for stock_code, status, last_time, data_count in recent_activity:
                    print(f"   {stock_code}: {status} (ë°ì´í„°: {data_count}ê°œ, ì‹œê°„: {last_time})")

                self.analysis_result['collection_progress'] = {
                    'status_distribution': dict(status_dist),
                    'attempt_distribution': dict(attempt_dist),
                    'total_tracked': total_progress,
                    'recent_activity': recent_activity
                }

        except Exception as e:
            print(f"âŒ ìˆ˜ì§‘ ì§„í–‰ìƒí™© ë¶„ì„ ì‹¤íŒ¨: {e}")

    def _analyze_data_quality(self):
        """ë°ì´í„° í’ˆì§ˆ ì²´í¬"""
        print(f"\nğŸ” 6. ë°ì´í„° í’ˆì§ˆ ì²´í¬")
        print("-" * 30)

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                quality_issues = []

                # stocks í…Œì´ë¸” í’ˆì§ˆ ì²´í¬
                print("ğŸ“ˆ stocks í…Œì´ë¸” í’ˆì§ˆ:")

                # NULL ê°’ ì²´í¬
                cursor.execute("""
                    SELECT 
                        SUM(CASE WHEN name IS NULL THEN 1 ELSE 0 END) as null_names,
                        SUM(CASE WHEN current_price IS NULL OR current_price = 0 THEN 1 ELSE 0 END) as null_prices,
                        SUM(CASE WHEN market IS NULL THEN 1 ELSE 0 END) as null_markets
                    FROM stocks
                """)

                null_stats = cursor.fetchone()
                if null_stats:
                    null_names, null_prices, null_markets = null_stats
                    print(f"   ğŸ“ ì¢…ëª©ëª… NULL: {null_names}ê°œ")
                    print(f"   ğŸ’° ê°€ê²© NULL/0: {null_prices}ê°œ")
                    print(f"   ğŸ¢ ì‹œì¥ NULL: {null_markets}ê°œ")

                    if null_names > 0:
                        quality_issues.append(f"ì¢…ëª©ëª… NULL {null_names}ê°œ")
                    if null_prices > 0:
                        quality_issues.append(f"ê°€ê²© NULL/0 {null_prices}ê°œ")

                # ì¼ë´‰ ë°ì´í„° í’ˆì§ˆ ì²´í¬ (ìƒ˜í”Œ)
                cursor.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name LIKE 'daily_prices_%'
                    LIMIT 3
                """)

                sample_tables = [row[0] for row in cursor.fetchall()]

                if sample_tables:
                    print(f"\nğŸ“Š ì¼ë´‰ ë°ì´í„° í’ˆì§ˆ (ìƒ˜í”Œ {len(sample_tables)}ê°œ):")

                    for table in sample_tables:
                        stock_code = table.replace('daily_prices_', '')

                        cursor.execute(f"""
                            SELECT 
                                COUNT(*) as total,
                                SUM(CASE WHEN close_price IS NULL OR close_price = 0 THEN 1 ELSE 0 END) as null_prices,
                                SUM(CASE WHEN volume IS NULL THEN 1 ELSE 0 END) as null_volumes
                            FROM {table}
                        """)

                        stats = cursor.fetchone()
                        if stats:
                            total, null_prices, null_volumes = stats
                            print(f"   ğŸ“ˆ {stock_code}: ê°€ê²©NULL {null_prices}/{total}, ê±°ë˜ëŸ‰NULL {null_volumes}/{total}")

                self.analysis_result['data_quality'] = {
                    'stocks_null_stats': null_stats,
                    'quality_issues': quality_issues,
                    'sample_daily_quality': sample_tables
                }

        except Exception as e:
            print(f"âŒ ë°ì´í„° í’ˆì§ˆ ì²´í¬ ì‹¤íŒ¨: {e}")

    def _analyze_performance(self):
        """ì„±ëŠ¥ ë¶„ì„"""
        print(f"\nâš¡ 7. ì„±ëŠ¥ ë¶„ì„")
        print("-" * 30)

        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.cursor()

                # ì¸ë±ìŠ¤ ì •ë³´
                cursor.execute("""
                    SELECT name, tbl_name FROM sqlite_master 
                    WHERE type='index' AND name NOT LIKE 'sqlite_%'
                    ORDER BY tbl_name
                """)

                indexes = cursor.fetchall()

                print(f"ğŸ“Š ì‚¬ìš©ì ì •ì˜ ì¸ë±ìŠ¤: {len(indexes)}ê°œ")
                for idx_name, table_name in indexes[:10]:
                    print(f"   ğŸ” {idx_name} (í…Œì´ë¸”: {table_name})")

                if len(indexes) > 10:
                    print(f"   ... ì™¸ {len(indexes) - 10}ê°œ")

                # í…Œì´ë¸”ë³„ í¬ê¸° ì¶”ì • (í˜ì´ì§€ ìˆ˜ ê¸°ë°˜)
                print(f"\nğŸ’¾ í…Œì´ë¸”ë³„ í¬ê¸° ì¶”ì •:")

                major_tables = ['stocks']
                cursor.execute("""
                    SELECT name FROM sqlite_master 
                    WHERE type='table' AND name LIKE 'daily_prices_%'
                    LIMIT 5
                """)
                major_tables.extend([row[0] for row in cursor.fetchall()])

                for table in major_tables:
                    try:
                        cursor.execute(f"SELECT COUNT(*) FROM {table}")
                        count = cursor.fetchone()[0]

                        # ëŒ€ëµì ì¸ í¬ê¸° ê³„ì‚° (ë ˆì½”ë“œë‹¹ í‰ê·  100ë°”ì´íŠ¸ ê°€ì •)
                        estimated_size_mb = (count * 100) / (1024 * 1024)

                        print(f"   ğŸ“‹ {table}: {count:,}ê°œ ë ˆì½”ë“œ (~{estimated_size_mb:.2f}MB)")

                    except Exception as e:
                        print(f"   âŒ {table}: ë¶„ì„ ì‹¤íŒ¨")

                self.analysis_result['performance'] = {
                    'index_count': len(indexes),
                    'indexes': indexes,
                    'major_tables_size': major_tables
                }

        except Exception as e:
            print(f"âŒ ì„±ëŠ¥ ë¶„ì„ ì‹¤íŒ¨: {e}")

    def _generate_migration_recommendations(self):
        """MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥ì‚¬í•­"""
        print(f"\nğŸš€ 8. MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥ì‚¬í•­")
        print("-" * 30)

        try:
            basic_info = self.analysis_result.get('basic_info', {})
            tables_info = self.analysis_result.get('tables', {})
            daily_analysis = self.analysis_result.get('daily_analysis', {})

            recommendations = []

            # 1. ë°ì´í„° ë³¼ë¥¨ ê¸°ë°˜ ê¶Œì¥ì‚¬í•­
            file_size_mb = basic_info.get('file_size_mb', 0)

            if file_size_mb > 100:
                recommendations.append("ğŸ”¥ DB í¬ê¸°ê°€ 100MB ì´ìƒ - MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê°•ë ¥ ê¶Œì¥")
            elif file_size_mb > 50:
                recommendations.append("âš¡ DB í¬ê¸°ê°€ 50MB ì´ìƒ - MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥")
            else:
                recommendations.append("â„¹ï¸ í˜„ì¬ í¬ê¸°ëŠ” ì‘ì§€ë§Œ í–¥í›„ í™•ì¥ì„ ìœ„í•´ MySQL ê³ ë ¤")

            # 2. í…Œì´ë¸” ìˆ˜ ê¸°ë°˜
            table_count = len(tables_info)
            daily_table_count = daily_analysis.get('table_count', 0)

            if daily_table_count > 100:
                recommendations.append("ğŸ“Š ì¼ë´‰ í…Œì´ë¸”ì´ 100ê°œ ì´ìƒ - íŒŒí‹°ì…”ë‹ ì „ëµ í•„ìš”")
            elif daily_table_count > 50:
                recommendations.append("ğŸ“Š ì¼ë´‰ í…Œì´ë¸”ì´ ë§ìŒ - í…Œì´ë¸” í†µí•© ê³ ë ¤")

            # 3. ì„±ëŠ¥ ìµœì í™”
            recommendations.append("ğŸ” ì¸ë±ìŠ¤ ì „ëµ: ë‚ ì§œ, ì¢…ëª©ì½”ë“œ ë³µí•© ì¸ë±ìŠ¤ í•„ìˆ˜")
            recommendations.append("ğŸ“… íŒŒí‹°ì…”ë‹: ë‚ ì§œë³„ íŒŒí‹°ì…”ë‹ìœ¼ë¡œ ì¿¼ë¦¬ ì„±ëŠ¥ í–¥ìƒ")

            # 4. ìŠ¤í‚¤ë§ˆ ê°œì„ 
            recommendations.append("ğŸ—„ï¸ í†µí•© í…Œì´ë¸”: daily_prices ë‹¨ì¼ í…Œì´ë¸”ë¡œ í†µí•© ê¶Œì¥")
            recommendations.append("ğŸ“ˆ ìƒˆ ë°ì´í„°: ìˆ˜ê¸‰ ë°ì´í„°ë¥¼ ìœ„í•œ ìŠ¤í‚¤ë§ˆ í™•ì¥ ì¤€ë¹„")

            # 5. ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ
            total_records = daily_analysis.get('total_records', 0)

            if total_records > 1000000:  # 100ë§Œ ë ˆì½”ë“œ ì´ìƒ
                recommendations.append("ğŸš€ ë°°ì¹˜ ë§ˆì´ê·¸ë ˆì´ì…˜: ì¢…ëª©ë³„ë¡œ ë‚˜ëˆ„ì–´ ì´ê´€ í•„ìš”")
            else:
                recommendations.append("ğŸš€ ì¼ê´„ ë§ˆì´ê·¸ë ˆì´ì…˜: ì „ì²´ ë°ì´í„° í•œë²ˆì— ì´ê´€ ê°€ëŠ¥")

            print("ğŸ’¡ ê¶Œì¥ì‚¬í•­:")
            for i, rec in enumerate(recommendations, 1):
                print(f"   {i}. {rec}")

            # MySQL ìŠ¤í‚¤ë§ˆ ì˜ˆìƒ í¬ê¸°
            estimated_mysql_size = file_size_mb * 1.2  # MySQLì€ ì¼ë°˜ì ìœ¼ë¡œ 20% ë” í¼
            print(f"\nğŸ’¾ ì˜ˆìƒ MySQL DB í¬ê¸°: {estimated_mysql_size:.2f}MB")

            self.analysis_result['migration_recommendations'] = {
                'recommendations': recommendations,
                'estimated_mysql_size_mb': round(estimated_mysql_size, 2),
                'migration_priority': 'HIGH' if file_size_mb > 100 else 'MEDIUM'
            }

        except Exception as e:
            print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥ì‚¬í•­ ìƒì„± ì‹¤íŒ¨: {e}")

    def _print_final_report(self):
        """ìµœì¢… ë¦¬í¬íŠ¸ ì¶œë ¥"""
        print(f"\nğŸ¯ 9. ìµœì¢… ë¶„ì„ ë¦¬í¬íŠ¸")
        print("=" * 60)

        try:
            basic_info = self.analysis_result.get('basic_info', {})
            stocks_analysis = self.analysis_result.get('stocks_analysis', {})
            daily_analysis = self.analysis_result.get('daily_analysis', {})

            print(f"ğŸ“Š ë°ì´í„°ë² ì´ìŠ¤ í˜„í™© ìš”ì•½:")
            print(f"   ğŸ’¾ DB í¬ê¸°: {basic_info.get('file_size_mb', 0):.2f}MB")
            print(f"   ğŸ“ˆ ì¢…ëª© ìˆ˜: {stocks_analysis.get('total_count', 0):,}ê°œ")
            print(f"   ğŸ“Š ì¼ë´‰ í…Œì´ë¸”: {daily_analysis.get('table_count', 0)}ê°œ")
            print(f"   ğŸ“‹ ì´ ì¼ë´‰ ë ˆì½”ë“œ: {daily_analysis.get('total_records', 0):,}ê°œ")

            # ë‚ ì§œ ë²”ìœ„
            date_range = daily_analysis.get('date_range')
            if date_range:
                print(f"   ğŸ“… ë°ì´í„° ê¸°ê°„: {date_range[0]} ~ {date_range[1]}")

            print(f"\nğŸ¯ ë‹¤ìŒ ë‹¨ê³„ ê¶Œì¥:")
            print(f"   1ï¸âƒ£ MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìˆ˜ë¦½")
            print(f"   2ï¸âƒ£ í†µí•© ìŠ¤í‚¤ë§ˆ ì„¤ê³„ (daily_prices ë‹¨ì¼ í…Œì´ë¸”)")
            print(f"   3ï¸âƒ£ ë°ì´í„° í’ˆì§ˆ ê°œì„ ")
            print(f"   4ï¸âƒ£ ì„±ëŠ¥ ìµœì í™” (ì¸ë±ì‹±, íŒŒí‹°ì…”ë‹)")

            # JSON ë¦¬í¬íŠ¸ ì €ì¥
            self._save_json_report()

        except Exception as e:
            print(f"âŒ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")

    def _save_json_report(self):
        """JSON í˜•íƒœë¡œ ë¶„ì„ ê²°ê³¼ ì €ì¥"""
        try:
            output_file = Path("database_analysis_report.json")

            # ë¶„ì„ ê²°ê³¼ì— íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ê°€
            self.analysis_result['analysis_timestamp'] = datetime.now().isoformat()
            self.analysis_result['analysis_version'] = "1.0"

            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.analysis_result, f, indent=2, ensure_ascii=False, default=str)

            print(f"\nğŸ’¾ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸ ì €ì¥: {output_file}")

        except Exception as e:
            print(f"âŒ JSON ë¦¬í¬íŠ¸ ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ” SQLite ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë¶„ì„ ë„êµ¬")
    print("=" * 60)
    print("ğŸ“‹ ë¶„ì„ í•­ëª©:")
    print("   1. ê¸°ë³¸ ì •ë³´ (íŒŒì¼ í¬ê¸°, ìˆ˜ì • ì‹œê°„)")
    print("   2. í…Œì´ë¸” êµ¬ì¡° ë° ë ˆì½”ë“œ ìˆ˜")
    print("   3. ì£¼ì‹ ê¸°ë³¸ì •ë³´ ë¶„ì„")
    print("   4. ì¼ë´‰ ë°ì´í„° ë¶„ì„")
    print("   5. ìˆ˜ì§‘ ì§„í–‰ìƒí™©")
    print("   6. ë°ì´í„° í’ˆì§ˆ ì²´í¬")
    print("   7. ì„±ëŠ¥ ë¶„ì„")
    print("   8. MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê¶Œì¥ì‚¬í•­")
    print("=" * 60)

    try:
        analyzer = DatabaseAnalyzer()

        # ë¶„ì„ ì‹¤í–‰
        result = analyzer.analyze_database()

        if 'error' in result:
            print(f"\nâŒ ë¶„ì„ ì‹¤íŒ¨: {result['error']}")
            return False

        print(f"\nâœ… ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì™„ë£Œ!")
        print(f"ğŸ“„ ìƒì„¸ ë¦¬í¬íŠ¸: database_analysis_report.json")

        return True

    except KeyboardInterrupt:
        print(f"\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ë¶„ì„ì„ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        return False
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        print(f"ìŠ¤íƒ íŠ¸ë ˆì´ìŠ¤:\n{traceback.format_exc()}")
        return False


class MySQLMigrationPlanner:
    """MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìˆ˜ë¦½ ë„êµ¬"""

    def __init__(self, analysis_result: dict):
        self.analysis_result = analysis_result

    def generate_migration_plan(self) -> dict:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìƒì„±"""
        print(f"\nğŸš€ MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìˆ˜ë¦½")
        print("-" * 40)

        plan = {
            'migration_strategy': self._determine_strategy(),
            'schema_design': self._design_mysql_schema(),
            'performance_optimization': self._plan_performance_optimization(),
            'data_migration_steps': self._plan_migration_steps(),
            'estimated_timeline': self._estimate_timeline()
        }

        return plan

    def _determine_strategy(self) -> dict:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ëµ ê²°ì •"""
        daily_analysis = self.analysis_result.get('daily_analysis', {})
        table_count = daily_analysis.get('table_count', 0)
        total_records = daily_analysis.get('total_records', 0)

        if table_count > 100 or total_records > 1000000:
            strategy = "GRADUAL"  # ì ì§„ì  ë§ˆì´ê·¸ë ˆì´ì…˜
            batch_size = 50  # í•œ ë²ˆì— 50ê°œ ì¢…ëª©ì”©
        else:
            strategy = "BULK"  # ì¼ê´„ ë§ˆì´ê·¸ë ˆì´ì…˜
            batch_size = table_count

        return {
            'type': strategy,
            'batch_size': batch_size,
            'parallel_processing': table_count > 50,
            'downtime_required': strategy == "BULK"
        }

    def _design_mysql_schema(self) -> dict:
        """MySQL ìŠ¤í‚¤ë§ˆ ì„¤ê³„"""
        return {
            'unified_daily_table': {
                'table_name': 'daily_prices',
                'partitioning': 'BY_DATE',  # ë‚ ì§œë³„ íŒŒí‹°ì…”ë‹
                'indexes': [
                    'PRIMARY KEY (stock_code, date)',
                    'INDEX idx_date (date)',
                    'INDEX idx_stock_code (stock_code)',
                    'INDEX idx_volume (volume)'
                ]
            },
            'stocks_table': {
                'enhancements': [
                    'Full-text search on name',
                    'JSON column for extended attributes',
                    'Improved indexing on market, market_cap'
                ]
            },
            'new_tables': [
                'supply_demand_data',  # ìˆ˜ê¸‰ ë°ì´í„°
                'minute_data',  # ë¶„ë´‰ ë°ì´í„°
                'market_events'  # ì‹œì¥ ì´ë²¤íŠ¸
            ]
        }

    def _plan_performance_optimization(self) -> dict:
        """ì„±ëŠ¥ ìµœì í™” ê³„íš"""
        return {
            'indexing_strategy': [
                'Composite indexes for common queries',
                'Covering indexes for read-heavy operations',
                'Partial indexes for filtered queries'
            ],
            'partitioning': {
                'daily_prices': 'RANGE partitioning by date (monthly)',
                'supply_demand': 'RANGE partitioning by date (monthly)',
                'minute_data': 'RANGE partitioning by date (weekly)'
            },
            'caching': [
                'Redis for frequently accessed stock info',
                'Query result caching for dashboard',
                'Connection pooling optimization'
            ]
        }

    def _plan_migration_steps(self) -> list:
        """ë§ˆì´ê·¸ë ˆì´ì…˜ ë‹¨ê³„ ê³„íš"""
        return [
            {
                'step': 1,
                'name': 'MySQL í™˜ê²½ ì¤€ë¹„',
                'tasks': [
                    'MySQL ì„œë²„ ì„¤ì¹˜ ë° ì„¤ì •',
                    'ë°ì´í„°ë² ì´ìŠ¤ ë° ì‚¬ìš©ì ìƒì„±',
                    'ìŠ¤í‚¤ë§ˆ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰'
                ],
                'estimated_time': '2ì‹œê°„'
            },
            {
                'step': 2,
                'name': 'stocks í…Œì´ë¸” ë§ˆì´ê·¸ë ˆì´ì…˜',
                'tasks': [
                    'SQLiteì—ì„œ stocks ë°ì´í„° ì¶”ì¶œ',
                    'MySQLë¡œ ë°ì´í„° ì´ê´€',
                    'ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦'
                ],
                'estimated_time': '30ë¶„'
            },
            {
                'step': 3,
                'name': 'daily_prices í†µí•© ë§ˆì´ê·¸ë ˆì´ì…˜',
                'tasks': [
                    'ì¢…ëª©ë³„ í…Œì´ë¸”ì„ ë‹¨ì¼ í…Œì´ë¸”ë¡œ í†µí•©',
                    'ë°°ì¹˜ë³„ ë°ì´í„° ì´ê´€',
                    'íŒŒí‹°ì…”ë‹ ì ìš©'
                ],
                'estimated_time': '2-4ì‹œê°„'
            },
            {
                'step': 4,
                'name': 'ì¸ë±ìŠ¤ ë° ìµœì í™”',
                'tasks': [
                    'ëª¨ë“  ì¸ë±ìŠ¤ ìƒì„±',
                    'ì„±ëŠ¥ í…ŒìŠ¤íŠ¸',
                    'ì¿¼ë¦¬ ìµœì í™”'
                ],
                'estimated_time': '1ì‹œê°„'
            },
            {
                'step': 5,
                'name': 'ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ë™',
                'tasks': [
                    'ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ë³€ê²½',
                    'ì—°ê²° í…ŒìŠ¤íŠ¸',
                    'ê¸°ëŠ¥ ê²€ì¦'
                ],
                'estimated_time': '1ì‹œê°„'
            }
        ]

    def _estimate_timeline(self) -> dict:
        """ì‘ì—… ì‹œê°„ ì˜ˆìƒ"""
        daily_analysis = self.analysis_result.get('daily_analysis', {})
        total_records = daily_analysis.get('total_records', 0)

        # ë ˆì½”ë“œ ìˆ˜ì— ë”°ë¥¸ ì‹œê°„ ê³„ì‚°
        if total_records > 5000000:  # 500ë§Œ ë ˆì½”ë“œ ì´ìƒ
            data_migration_hours = 8
        elif total_records > 1000000:  # 100ë§Œ ë ˆì½”ë“œ ì´ìƒ
            data_migration_hours = 4
        else:
            data_migration_hours = 2

        return {
            'total_estimated_time': f"{2 + data_migration_hours + 3}ì‹œê°„",
            'preparation': '2ì‹œê°„',
            'data_migration': f'{data_migration_hours}ì‹œê°„',
            'optimization': '2ì‹œê°„',
            'testing': '1ì‹œê°„',
            'recommended_schedule': 'Weekend deployment'
        }


def generate_migration_plan(analysis_file: str = "database_analysis_report.json"):
    """ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìƒì„±"""
    try:
        # ë¶„ì„ ê²°ê³¼ ë¡œë“œ
        with open(analysis_file, 'r', encoding='utf-8') as f:
            analysis_result = json.load(f)

        # ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìƒì„±
        planner = MySQLMigrationPlanner(analysis_result)
        plan = planner.generate_migration_plan()

        # ê³„íš ì €ì¥
        plan_file = "mysql_migration_plan.json"
        with open(plan_file, 'w', encoding='utf-8') as f:
            json.dump(plan, f, indent=2, ensure_ascii=False, default=str)

        print(f"ğŸ“‹ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ì €ì¥: {plan_file}")

        return plan

    except Exception as e:
        print(f"âŒ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìƒì„± ì‹¤íŒ¨: {e}")
        return None


if __name__ == "__main__":
    try:
        # 1. ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì‹¤í–‰
        print("ğŸš€ 1ë‹¨ê³„: ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ ë¶„ì„")
        success = main()

        if success:
            print(f"\nğŸš€ 2ë‹¨ê³„: MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìˆ˜ë¦½")
            plan = generate_migration_plan()

            if plan:
                print(f"\nâœ… ë¶„ì„ ë° ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìˆ˜ë¦½ ì™„ë£Œ!")
                print(f"ğŸ“„ ìƒì„±ëœ íŒŒì¼:")
                print(f"   ğŸ“Š database_analysis_report.json")
                print(f"   ğŸš€ mysql_migration_plan.json")
                print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
                print(f"   1. ë¶„ì„ ë¦¬í¬íŠ¸ ê²€í† ")
                print(f"   2. ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìŠ¹ì¸")
                print(f"   3. MySQL í™˜ê²½ ì¤€ë¹„")
                print(f"   4. ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰")
            else:
                print(f"âš ï¸ ë§ˆì´ê·¸ë ˆì´ì…˜ ê³„íš ìˆ˜ë¦½ì€ ì‹¤íŒ¨í–ˆì§€ë§Œ ë¶„ì„ì€ ì™„ë£Œë¨")
        else:
            print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ë¶„ì„ ì‹¤íŒ¨")

    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        sys.exit(1)