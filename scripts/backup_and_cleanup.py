#!/usr/bin/env python3
"""
íŒŒì¼ ê²½ë¡œ: scripts/backup_and_cleanup.py

í”„ë¡œì íŠ¸ ë°±ì—… ìƒì„± ë° ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬ ìŠ¤í¬ë¦½íŠ¸
- í˜„ì¬ ìƒíƒœ ë°±ì—…
- ë¶ˆí•„ìš”í•œ íŒŒì¼ ì•ˆì „ ì‚­ì œ
- í´ë” êµ¬ì¡° ìµœì í™”
"""

import os
import shutil
import zipfile
from datetime import datetime
from pathlib import Path
import json


class ProjectCleanup:
    """í”„ë¡œì íŠ¸ ì •ë¦¬ ë° ë°±ì—… í´ë˜ìŠ¤"""

    def __init__(self):
        self.project_root = Path.cwd()
        self.backup_dir = self.project_root / "backups"
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # ì‚­ì œ ëŒ€ìƒ íŒŒì¼ë“¤
        self.files_to_remove = [
            "scripts/clean_database.py",
            "scripts/analyze_database_status.py",
            "scripts/restructure_mysql_to_separate_tables.py",
            "scripts/sync_sqlite_to_mysql_incremental.py",
            "config/database.yaml"  # SQLite ì „ìš© ì„¤ì •
        ]

        # ì‚­ì œ ëŒ€ìƒ í´ë”ë“¤
        self.dirs_to_remove = [
            "logs",  # ì„ì‹œ ë¡œê·¸ë“¤ (í•„ìš”ì‹œ ì¬ìƒì„±)
            "__pycache__",  # Python ìºì‹œ
            ".pytest_cache"  # í…ŒìŠ¤íŠ¸ ìºì‹œ
        ]

        # ë°±ì—…ì—ì„œ ì œì™¸í•  í•­ëª©ë“¤
        self.backup_exclude = [
            "data/*.db",
            "data/*.sqlite*",
            "logs/*.log",
            "**/__pycache__",
            "**/*.pyc",
            ".git",
            "venv*",
            "env*",
            "backups"
        ]

    def create_backup(self) -> bool:
        """í˜„ì¬ í”„ë¡œì íŠ¸ ìƒíƒœ ë°±ì—…"""
        print("ğŸ“¦ 1ë‹¨ê³„: í”„ë¡œì íŠ¸ ë°±ì—… ìƒì„±")
        print("=" * 50)

        try:
            # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
            self.backup_dir.mkdir(exist_ok=True)

            # ë°±ì—… íŒŒì¼ ì´ë¦„
            backup_filename = f"stock_trading_backup_{self.timestamp}.zip"
            backup_path = self.backup_dir / backup_filename

            print(f"ğŸ“ ë°±ì—… ìœ„ì¹˜: {backup_path}")
            print(f"â³ ë°±ì—… ìƒì„± ì¤‘...")

            # ZIP íŒŒì¼ ìƒì„±
            with zipfile.ZipFile(backup_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
                self._add_to_zip(zipf, self.project_root)

            # ë°±ì—… ë©”íƒ€ë°ì´í„° ìƒì„±
            metadata = {
                "backup_date": datetime.now().isoformat(),
                "backup_purpose": "Git í™˜ê²½ ì •ë¦¬ ì „ ë°±ì—…",
                "project_state": "MySQL ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ, 62.7% ë°ì´í„° ìˆ˜ì§‘ ì™„ë£Œ",
                "files_count": self._count_files_in_zip(backup_path)
            }

            metadata_path = self.backup_dir / f"backup_metadata_{self.timestamp}.json"
            with open(metadata_path, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, indent=2, ensure_ascii=False)

            file_size = backup_path.stat().st_size / (1024 * 1024)  # MB
            print(f"âœ… ë°±ì—… ì™„ë£Œ!")
            print(f"   ğŸ“ íŒŒì¼: {backup_filename}")
            print(f"   ğŸ“Š í¬ê¸°: {file_size:.1f}MB")
            print(f"   ğŸ“‹ ë©”íƒ€ë°ì´í„°: backup_metadata_{self.timestamp}.json")

            return True

        except Exception as e:
            print(f"âŒ ë°±ì—… ì‹¤íŒ¨: {e}")
            return False

    def _add_to_zip(self, zipf, folder):
        """í´ë”ë¥¼ ZIPì— ì¶”ê°€ (ì œì™¸ íŒ¨í„´ ì ìš©)"""
        for file_path in folder.rglob("*"):
            if file_path.is_file() and not self._should_exclude(file_path):
                # ìƒëŒ€ ê²½ë¡œë¡œ ì¶”ê°€
                relative_path = file_path.relative_to(self.project_root)
                zipf.write(file_path, relative_path)

    def _should_exclude(self, file_path: Path) -> bool:
        """íŒŒì¼ì´ ë°±ì—…ì—ì„œ ì œì™¸ë˜ì–´ì•¼ í•˜ëŠ”ì§€ í™•ì¸"""
        relative_path = file_path.relative_to(self.project_root)
        path_str = str(relative_path).replace('\\', '/')

        for pattern in self.backup_exclude:
            if self._match_pattern(path_str, pattern):
                return True
        return False

    def _match_pattern(self, path: str, pattern: str) -> bool:
        """ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­"""
        if '**' in pattern:
            # **/*.pyc ê°™ì€ íŒ¨í„´
            parts = pattern.split('**/')
            if len(parts) == 2:
                return path.endswith(parts[1].replace('*', ''))
        elif '*' in pattern:
            # data/*.db ê°™ì€ íŒ¨í„´
            import fnmatch
            return fnmatch.fnmatch(path, pattern)
        else:
            # ì •í™•í•œ ë§¤ì¹­
            return path == pattern or path.endswith('/' + pattern)
        return False

    def _count_files_in_zip(self, zip_path: Path) -> int:
        """ZIP íŒŒì¼ ë‚´ íŒŒì¼ ìˆ˜ ì¹´ìš´íŠ¸"""
        try:
            with zipfile.ZipFile(zip_path, 'r') as zipf:
                return len(zipf.namelist())
        except:
            return 0

    def cleanup_files(self) -> bool:
        """ë¶ˆí•„ìš”í•œ íŒŒì¼ë“¤ ì •ë¦¬"""
        print(f"\nğŸ—‘ï¸ 2ë‹¨ê³„: ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬")
        print("=" * 50)

        removed_files = []
        removed_dirs = []

        try:
            # íŒŒì¼ ì‚­ì œ
            print("ğŸ“„ ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ:")
            for file_path in self.files_to_remove:
                full_path = self.project_root / file_path
                if full_path.exists():
                    full_path.unlink()
                    removed_files.append(file_path)
                    print(f"   âœ… ì‚­ì œ: {file_path}")
                else:
                    print(f"   âš ï¸ ì—†ìŒ: {file_path}")

            # í´ë” ì‚­ì œ
            print(f"\nğŸ“ ë¶ˆí•„ìš”í•œ í´ë” ì‚­ì œ:")
            for dir_path in self.dirs_to_remove:
                full_path = self.project_root / dir_path
                if full_path.exists() and full_path.is_dir():
                    shutil.rmtree(full_path)
                    removed_dirs.append(dir_path)
                    print(f"   âœ… ì‚­ì œ: {dir_path}/")
                else:
                    print(f"   âš ï¸ ì—†ìŒ: {dir_path}/")

            # Python ìºì‹œ ì¬ê·€ì  ì‚­ì œ
            print(f"\nğŸ§¹ Python ìºì‹œ ì •ë¦¬:")
            cache_count = self._remove_python_cache()
            print(f"   âœ… __pycache__ í´ë” {cache_count}ê°œ ì‚­ì œ")

            # ì •ë¦¬ ê²°ê³¼ ì €ì¥
            cleanup_report = {
                "cleanup_date": datetime.now().isoformat(),
                "removed_files": removed_files,
                "removed_directories": removed_dirs,
                "python_cache_cleaned": cache_count,
                "status": "success"
            }

            report_path = self.backup_dir / f"cleanup_report_{self.timestamp}.json"
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(cleanup_report, f, indent=2, ensure_ascii=False)

            print(f"\nâœ… ì •ë¦¬ ì™„ë£Œ!")
            print(f"   ğŸ“„ ì‚­ì œëœ íŒŒì¼: {len(removed_files)}ê°œ")
            print(f"   ğŸ“ ì‚­ì œëœ í´ë”: {len(removed_dirs)}ê°œ")
            print(f"   ğŸ“‹ ì •ë¦¬ ë¦¬í¬íŠ¸: cleanup_report_{self.timestamp}.json")

            return True

        except Exception as e:
            print(f"âŒ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False

    def _remove_python_cache(self) -> int:
        """Python ìºì‹œ í´ë”ë“¤ ì¬ê·€ì  ì‚­ì œ"""
        count = 0
        for cache_dir in self.project_root.rglob("__pycache__"):
            if cache_dir.is_dir():
                shutil.rmtree(cache_dir)
                count += 1
        return count

    def optimize_structure(self) -> bool:
        """í´ë” êµ¬ì¡° ìµœì í™”"""
        print(f"\nğŸ“ 3ë‹¨ê³„: í´ë” êµ¬ì¡° ìµœì í™”")
        print("=" * 50)

        try:
            # í•„ìˆ˜ í´ë”ë“¤ ìƒì„±
            essential_dirs = [
                "data",
                "logs",
                "scripts/utils",
                "src/core",
                "src/api",
                "src/collectors",
                "src/utils"
            ]

            created_dirs = []
            for dir_path in essential_dirs:
                full_path = self.project_root / dir_path
                if not full_path.exists():
                    full_path.mkdir(parents=True, exist_ok=True)
                    created_dirs.append(dir_path)
                    print(f"   âœ… ìƒì„±: {dir_path}/")

            # .gitkeep íŒŒì¼ ìƒì„± (ë¹ˆ í´ë” ìœ ì§€ìš©)
            gitkeep_dirs = ["data", "logs"]
            for dir_name in gitkeep_dirs:
                gitkeep_path = self.project_root / dir_name / ".gitkeep"
                if not gitkeep_path.exists():
                    gitkeep_path.touch()
                    print(f"   ğŸ“Œ .gitkeep ìƒì„±: {dir_name}/")

            if created_dirs:
                print(f"\nâœ… êµ¬ì¡° ìµœì í™” ì™„ë£Œ! ({len(created_dirs)}ê°œ í´ë” ìƒì„±)")
            else:
                print(f"\nâœ… í´ë” êµ¬ì¡° ì´ë¯¸ ìµœì í™”ë¨!")

            return True

        except Exception as e:
            print(f"âŒ êµ¬ì¡° ìµœì í™” ì‹¤íŒ¨: {e}")
            return False

    def show_final_structure(self):
        """ìµœì¢… í”„ë¡œì íŠ¸ êµ¬ì¡° í‘œì‹œ"""
        print(f"\nğŸ“‹ 4ë‹¨ê³„: ìµœì¢… í”„ë¡œì íŠ¸ êµ¬ì¡°")
        print("=" * 50)

        def print_tree(path: Path, prefix: str = "", max_depth: int = 3, current_depth: int = 0):
            if current_depth >= max_depth:
                return

            items = sorted([p for p in path.iterdir() if not p.name.startswith('.')],
                           key=lambda x: (x.is_file(), x.name.lower()))

            for i, item in enumerate(items):
                is_last = i == len(items) - 1
                current_prefix = "â””â”€â”€ " if is_last else "â”œâ”€â”€ "
                next_prefix = "    " if is_last else "â”‚   "

                if item.is_dir():
                    print(f"{prefix}{current_prefix}ğŸ“ {item.name}/")
                    if current_depth < max_depth - 1:
                        print_tree(item, prefix + next_prefix, max_depth, current_depth + 1)
                else:
                    icon = "ğŸ" if item.suffix == ".py" else "ğŸ“„"
                    print(f"{prefix}{current_prefix}{icon} {item.name}")

        print("ğŸ—ï¸ stock-trading-system/")
        print_tree(self.project_root, max_depth=3)

        # ìš”ì•½ ì •ë³´
        py_files = list(self.project_root.rglob("*.py"))
        print(f"\nğŸ“Š í”„ë¡œì íŠ¸ ìš”ì•½:")
        print(f"   ğŸ Python íŒŒì¼: {len(py_files)}ê°œ")
        print(f"   ğŸ“ ì£¼ìš” í´ë”: src/, scripts/, data/, logs/")
        print(f"   ğŸ¯ ìƒíƒœ: Git í™˜ê²½ ìµœì í™” ì™„ë£Œ!")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ì£¼ì‹ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ - Git í™˜ê²½ ì •ë¦¬")
    print("=" * 60)
    print("ğŸ“‹ ì‘ì—… ê³„íš:")
    print("   1ï¸âƒ£ í˜„ì¬ ìƒíƒœ ë°±ì—… ìƒì„±")
    print("   2ï¸âƒ£ ë¶ˆí•„ìš”í•œ íŒŒì¼ ì •ë¦¬")
    print("   3ï¸âƒ£ í´ë” êµ¬ì¡° ìµœì í™”")
    print("   4ï¸âƒ£ ìµœì¢… êµ¬ì¡° í™•ì¸")
    print("=" * 60)

    # ì‚¬ìš©ì í™•ì¸
    response = input("\nê³„ì† ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/N): ")
    if response.lower() not in ['y', 'yes']:
        print("âŒ ì‘ì—…ì´ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤.")
        return False

    cleanup = ProjectCleanup()

    # 1ë‹¨ê³„: ë°±ì—… ìƒì„±
    if not cleanup.create_backup():
        print("âŒ ë°±ì—… ì‹¤íŒ¨ë¡œ ì¸í•´ ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        return False

    # 2ë‹¨ê³„: íŒŒì¼ ì •ë¦¬
    if not cleanup.cleanup_files():
        print("âš ï¸ íŒŒì¼ ì •ë¦¬ì— ë¬¸ì œê°€ ìˆì—ˆì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")

    # 3ë‹¨ê³„: êµ¬ì¡° ìµœì í™”
    if not cleanup.optimize_structure():
        print("âš ï¸ êµ¬ì¡° ìµœì í™”ì— ë¬¸ì œê°€ ìˆì—ˆì§€ë§Œ ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")

    # 4ë‹¨ê³„: ìµœì¢… êµ¬ì¡° í‘œì‹œ
    cleanup.show_final_structure()

    print("\n" + "=" * 60)
    print("ğŸ‰ Git í™˜ê²½ ì •ë¦¬ ì™„ë£Œ!")
    print("ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„: README ë° ë¬¸ì„œ ì—…ë°ì´íŠ¸")
    print("ğŸ“¦ ë°±ì—… ìœ„ì¹˜: backups/ í´ë”")

    return True


if __name__ == "__main__":
    main()